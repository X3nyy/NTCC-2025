{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "In this notebook, we will perform exploratory data analysis (EDA) on the mental health datasets. The goal is to understand the data better, identify patterns, and prepare for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load datasets\n",
    "twitter_df = pd.read_csv('data/raw/twitter_mental_health.csv')\n",
    "reddit_df = pd.read_csv('data/raw/reddit_mental_health.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f'Twitter Dataset shape: {twitter_df.shape}')\n",
    "print(f'Reddit Dataset shape: {reddit_df.shape}')\n",
    "\n",
    "# Sample data\n",
    "print(twitter_df.head())\n",
    "print(reddit_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "Let's visualize the distribution of mental health conditions in the Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = twitter_df['label'].value_counts()\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Distribution of Mental Health Conditions in Twitter Dataset')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/figures/twitter_class_distribution.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length Analysis\n",
    "\n",
    "We will analyze the length of the text in the Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "twitter_df['text_length'] = twitter_df['text'].apply(len)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=twitter_df, x='text_length', bins=50, kde=True)\n",
    "plt.title('Text Length Distribution in Twitter Dataset')\n",
    "plt.xlabel('Character Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/figures/twitter_text_length.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency Analysis\n",
    "\n",
    "Let's analyze the most common words used in the Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_top_words(texts, n=20):\n",
    "    all_words = ' '.join(texts).lower()\n",
    "    all_words = re.sub(r'[^\w\s]', '', all_words)\n",
    "    words = all_words.split()\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "# Get top words for each condition\n",
    "for condition in twitter_df['label'].unique():\n",
    "    condition_texts = twitter_df[twitter_df['label'] == condition]['text']\n",
    "    top_words = get_top_words(condition_texts)\n",
    "    print(f'Top 20 words for {condition}:')\n",
    "    for word, count in top_words:\n",
    "        print(f'{word}: {count}')\n",
    "    \n",
    "    # Generate word cloud\n",
    "    all_words = ' '.join(condition_texts).lower()\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
    "                         max_words=100, stopwords=nltk.corpus.stopwords.words('english')).generate(all_words)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for {condition}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'reports/figures/wordcloud_{condition}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we performed exploratory data analysis on the Twitter mental health dataset. We visualized class distributions, analyzed text lengths, and examined word frequencies. These insights will guide our preprocessing and modeling efforts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "application/x-ipynb+json",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}